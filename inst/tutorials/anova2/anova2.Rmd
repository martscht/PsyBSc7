---
title: "Sitzung 10: ANOVA II (zweifaktoriell)"
output: 
  learnr::tutorial:
    progressive: false
    allow_skip: true
    includes:
      after_body: footer.html
      in_header: header.html
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
library(ez)
library(emmeans)

data(conspiracy, package = 'PsyBSc7')

knitr::opts_chunk$set(echo = FALSE)
```

## Übungs-Datensatz

```{r}
conspiracy <- readRDS('conspiracy.rds')
dim(conspiracy)
head(conspiracy)
```

Der Datensatz enthält die Werte von 2451 Personen auf 9 Variablen und stammt aus einer Untersuchung zum Thema verschwörungstheoretische Überzegungen. Die ersten vier Variablen enthalten Informationen über den demographischen Hintergrund der Personen: höchster Bildungsabschluss, Typ des Wohnortes, Geschlecht und Alter. Die fünf restlichen Variablen sind Skalenwerte bezüglich verschiedener subdimensionen verschwörungstheoretischer Überzeugungen: GM (goverment malfeasance), MG (malevolent global conspiracies), ET (extraterrestrial cover-up), PW (personal well-being) und CI (control of information).

## Einfaktorielle ANOVA

In der letzten Sitzung zeigte sich, dass die Überzeugung, dass die Existenz von Außerirdischen durch eine globale Verschwörung verdeckt wird, von dem höchsten Bildungsabschluss (`edu`) und von der Art des Wohngebiets (`urban`) abhängig ist. Zur Berechnung der einfaktoriellen ANOVAs wurde das `ez`-Paket verwendet:

```{r}
library(ez)
```

Wie schon in der letzten Sitzung, ist es zunächst erforderlich eine Personen-ID zu erzeugen. In diesem Fall kann einfach die Zeilennummer einer Person genutzt werden:

```{r}
conspiracy$id <- as.factor(1:nrow(conspiracy))
```

Die einfaktorielle ANOVA ergab bezüglich des Wohnortes:

```{r}
ezANOVA(conspiracy, wid = id, dv = ET, between = urban, detailed = TRUE)
```

und die Ergebnisse aus den Übungsuafgaben ergaben bezüglich des Bildungabschlusses:

```{r}
ezANOVA(conspiracy, wid = id, dv = ET, between = edu, detailed = TRUE)
```

Um dies rein deskriptiv anhand der gruppenspezifischen Mittelwerte zu betrachten, kann mit einer Vielzahl von Funktionen gearbeitet werden. Eine gängige Variante ist der `tapply`-Befehl:

```{r}
tapply(conspiracy$ET, list(conspiracy$urban), mean)
tapply(conspiracy$ET, list(conspiracy$edu), mean)
```

Mögliche Alternativen:

```{r, eval = FALSE}
# Mithilfe des aggregate-Befehls
aggregate(conspiracy$ET, conspiracy$urban, mean)
aggregate(conspiracy$ET, conspiracy$edu, mean)

# Mithilfe des describeBy aus dem psych-Paket
describeBy(conspiracy$ET, conspiracy$urban)
describeBy(conspiracy$ET, conspiracy$edu)
```

## Deskriptive Darstellung der Kombinationen

In der mehrfaktoriellen ANOVA steht nicht nur der Vergleich von Gruppen anhand *einer* unabhängigen Variable im Mittelpunkt, sondern der Fokus liegt auf der *Kombination von Gruppierungen* anhand mehrerer unabhängiger Variablen. Deksriptiv können die Mittelwerte aus Gruppenkombinationen ebenfalls mit der `tapply`-Funktion bestimmt werden:

```{r}
# Gruppierungskombinationen erstellen
kombi <- conspiracy[, c('urban', 'edu')]

# Kombinationsspezifische Mittelwertetabelle
tapply(conspiracy$ET, kombi, mean)
```

Im `ez`-Paket sind neben den Funktionen zur direkten Berechnung von Varianzanalysen auch einige zusätzliche Hilfefunktionen integriert. Dazu gehört auch die `ezStats`-Funktion, die die Darstellung von Gruppengrößen, Mittelwerten und Standardabweichungen innerhalb der einzelnen Gruppenkombinationen erlaubt. Die Argumente, die diese Funktion erwartet sind analog zu denen in der `ezANOVA`-Funktion:

  - `data = `: der genutzte Datensatz
  - `wid = `: eine Personen ID-Variable
  - `dv = `: die abhängige Variable (dependent variable)
  - `between = `: eine Gruppierungsvariable (die *zwischen* Personen unterscheidet)

Um mehrere Variablen als unabhängige Variablen zu deklarieren, kann mit dem `c()` ein Vektor eröffnet werden, der an das Argument `between` weitergegeben wird. 

```{r}
ezStats(conspiracy, dv = ET, wid = id, between = c(urban, edu))
```

Neben $N$, $\bar{x}$ und $\sigma$ wird in der Ausgabe auch Fishers Least Significant Difference ausgebeben. Diese kennzeichnet den minimalen Mittelwertsunterschied, der im direkten Vergleich zweier Gruppen signifkant wäre. Schon an dieser Stelle werden wir von `ez` darauf hingewiesen, dass die Gruppen ungleich groß sind und dies in der ANOVA zu Problemen führen könnte.

Für eine grafische Darstellung der Mittelwerte, kann `ezPlot` benutzt werden. Der Befehl nimmt die gleichen Argumente entgegen wie `ezStats`, benötigt aber zusätzlich eine Aussage darüber, welche Variable auf der x-Achse abgetragen werden soll (`x = `) und welche Variable farblich unterschieden werden soll (`split = `).

```{r}
ezPlot(conspiracy, dv = ET, wid = id, between = c(urban, edu),
  x = urban, split = edu)
```

Wie zu erkennen ist, übersetzt die `ezPlot` Funktion die Eingabe in einen `ggplot`. Die FLSD wird hier in Form von Error-Bars dargestellt - durch diese kann also abgeschätzt werden, welche Mittelwerte sich statistisch bedeutsam unterscheiden.


## Zweifaktorielle Varianzanalyse

Mithilfe der zweifaktoriellen Varianzanalyse können drei zentralen Fragen beantwortet werden (Eid, Gollwitzer & Schmitt, 2015, S. 432): 

  1. Lassen sich Unterschiede in der AV auf Unterschiede in der 1. UV zurückführen? (Haupteffekt 1)
  2. Lassen sich Unterschiede in der AV auf Unterschiede in der 2. UV zurückführen? (Haupteffekt 2)
  3. Hängt der Einfluss der 1. UV auf die AV von der 2. UV ab, bzw. hängt der Einfluss der 2. UV von der 1. UV ab? (Interaktionseffekt)
  
Im Beispiel wären die Fragen also:

  1. Lassen sich Unterschiede in der ET-Überzeugung (`ET`) auf die Art des Wohnorts (`urban`) zurückführen?
  2. Lassen sich Unterschiede in der ET-Überzeugung (`ET`) auf das Bildungsniveau (`edu`) zurückführen?
  3. Unterschieden sich die Unterschiede aufgrund der Art des Wohnorts (`urban`) zwischen den Bildungsniveaus (`edu`)?

Deskriptiv lässt sich ein Hinweis auf eine Antwort zur 3. Frage in der Abbildung der Mittelwerte darin erkennen, dass innerhalb der Gruppe mit ländlichem Wohnort (`rural`) Personen ohne Highschool Abschluss eine höhere verschwörungstheoretische Überzeugung aufweisen als Personen mit höheren Bildungsabschlüssen, wohingegen sie in den beiden anderen Wohnort-Gruppen einen niedrigeren ET-Wert aufweisen als Personen mit Highschool Abschluss.

Etwas technischer Ausgedrückt, lassen sich die drei Fragen in Hypothesenpaaren formulieren (Eid, Gollwitzer & Schmitt, 2015, S. 442):

  1. $H_0: \mu_{j \bullet} - \mu = 0$, $H_1: \mu_{j \bullet} - \mu \neq 0$
  2. $H_0: \mu_{\bullet k} - \mu = 0$, $H_1: \mu_{\bullet k} - \mu \neq 0$
  3. $H_0: \mu_{jk} - \mu_{j \bullet} - \mu_{\bullet k} + \mu = 0$, $H_0: \mu_{jk} - \mu_{j \bullet} - \mu_{\bullet k} + \mu \neq 0$

Die drei Nullhypothesen werden in der zweifaktoriellen ANOVA geprüft. Die für `ezStats` genutzten Argumente können auch für `ezANOVA` benutzt werden. Um eine etwas detailliertere Ausgabe zu erhalten, kann zudem `detailed = TRUE` gesetzt werden.

```{r}
ezANOVA(conspiracy, dv = ET, wid = id, between = c(urban, edu), detailed = TRUE)
```

Der Levene Test fällt in diesem Fall statistisch bedeutsam aus, sodass die Homoskedastizitätsannahme (in diesem Fall: die Varianz ist in allen 9 Gruppen identisch) verworfen werden muss. `ezANOVA` liefert eine eingebaute Korrekturmöglichkeit (HC3 von MacKinnon J. G. & White H., 1985), die mithilfe `white.adjust = TRUE` angefordert werden kann:

```{r}
ezANOVA(conspiracy, dv = ET, wid = id, between = c(urban, edu), detailed = TRUE, white.adjust = TRUE)
```

In diesem Fall werden beide Haupteffekte statistisch bedeutsam, die Interaktion allerdings nicht. Inhaltlich heißt das, dass sowohl die Art des Wohnorts als auch das Bildungsniveau einen Einfluss auf die verschwörungstheoretische Überzeugung haben. Über die jeweiligen Effekte hinaus, ist die spezifische Kombination aus Wohnort und Bildungsniveau für diese Überzeugung irrelevant.


## Post-Hoc Analyse und Kontraste

Mit Tukeys Honest Significant Difference können, wie auch letzte Sitzung, alle möglichen Gruppenkombinationen verglichen werden. In diesem Fall ergeben sich allerdings 36 Vergleiche, sodass es außerordentlich ineffizient ist, alle Tests durchzuführen. 

```{r}
TukeyHSD(aov(ET ~ urban*edu, conspiracy))
```

Durch die Grundgedanken des klassischen Nullhypothesentestens muss das $\alpha$-Fehlerniveau auf alle *durchgeführten* Tests korrigiert werden. In dieser Stelle können daher *geplante Kontraste* genutzt werden, um a-priori definierte, theoretisch relevante Vergleich durchzuführen. Dafür ist das `emmeans`-Paket empfehlenswert:

```{r}
library(emmeans)
```

Um Kontraste definieren zu können, müssen wir zunächst in Erfahrung bringen, in welcher Reihenfolge die Gruppenkombinationen intern repräsentiert werden. Dafür kann man mit der `emmeans`-Funktion ein Objekt anlegen, welches alle Kombinationen enthält. Als Argument erwartet die Funktion ein `aov`-Objekt (wie auch die `TukeyHSD`-Funktion) und eine Angabe der relevanten unabhängigen Variablen:

```{r}
emm <- emmeans(aov(ET ~ urban*edu, conspiracy), ~ urban * edu)
emm
```

Mithilfe eines 9 Elemente langen Vektors können Kontraste festgelegt werden. Um z.B. die Gruppe "rural, not highschool" mit der Gruppe "suburban, not highschool" zu vergleichen, kann folgender Vektor angelegt werden:

```{r}
cont1 <- c(1, -1, 0, 0, 0, 0, 0, 0, 0)
```

Die Nullhypothese, die durch diesen Vektor geprüft wird, lässt sich mithilfe der Reihenfolge der Gruppen leicht zusammenstellen. Wenn $j$ die drei Stufen von `urban` indiziert (1 = rural, 2 = suburban, 3 = urban) und $k$ die drei Stufen von `edu` (1 = not highschool, 2 = highschool, 3 = college), ist die durch `cont1` festgelegte Nullhypothese:

$H_0: 1 \cdot \mu_{11} - 1 \cdot \mu_{21} + 0 \cdot \mu_{31} + 0 \cdot \mu_{12} + 0 \cdot \mu_{22} + 0 \cdot \mu_{32} + 0 \cdot \mu_{13} + 0 \cdot \mu_{23} + 0 \cdot \mu_{33} = 0$

Oder gekürzt:

$H_0: \mu_{11} - \mu_{21} = 0$

Mit dem `contrast`-Befehl kann der festgelegte Kontrast geprüft werden:

```{r}
contrast(emm, list(cont1))
```

Dieser Kontrast entspricht dem ersten Vergleich des oben durchgeführten `TukeyHSD`, unterscheidet sich jedoch im $p$-Wert. Der hier bestimmte $p$-Wert ist nicht korrigiert (weil nur ein Kontrast geprüft wurde), der oben aufgeführte hingegen auf 36 Tests Bonferroni korrigiert.

Mithilfe der Kontrast-Vektoren können komplexe Hypothesen geprüft werden. Beispielsweise könnten wir vergleichen, inwiefern sich Personen aus städtischer Umgebung ($j = 3$) mit mindestens High School Abschluss von Personen ohne High School Abschluss unterscheiden:

```{r}
cont2 <- c(0, 0, 1, 0, 0, -.5, 0, 0, -.5)
```

oder in Hypothesenform: $H_0: \mu_{31} - .5 \cdot \mu_{32} - .5 \cdot \mu_{33} = 0$ bzw. $H_0: \mu_{31} - \frac{\mu_{32} + \mu_{33}}{2} = 0$. Eine generelle Daumenregel besagt, dass die Summe des Kontrastvektors 0 sein sollte.

Weil sowohl `cont1` als auch `cont2` durchgeführt werden, muss für das multiple Testen der beiden korrigiert werden. Das kann dadurch erreicht werden, dass im `contrast`-Befehl alle Kontraste gleichzeitig eingeschlossen werden und mit `adjust = 'bonferroni'` z.B. die Bonferroni-Korrektur ausgewählt wird:

```{r}
contrast(emm, list(cont1, cont2), adjust = 'bonferroni')
```

## Zusatz: Quadratsummen-Typ

Bei mehrfaktoriellen ANOVAs können die Quadratsummen auf unterschiedliche Arten berechnet werden. Verbreitet sind dabei 3 Typen, zwischen denen man sich anhand der inhaltlichen Hypothesen entscheiden sollte.

Typ I berücksichtigt in der Berechnung der Quadratsummen nur die vorherigen unabhängigen Variablen. Dies entspricht konzeptuell der sequentiellen Aufnahme von Prädiktoren in der Regression.

```{r}
# QS-Typ 1, Reihenfolge 1
ezANOVA(conspiracy, dv = ET, wid = id, between = c(urban, edu), type = 1)

# QS-Typ 1, Reihenfolge 2
ezANOVA(conspiracy, dv = ET, wid = id, between = c(edu, urban), type = 1)
```

Typ II berücksichtigt in der Berechnung alle anderen unabhängigen Variablen. In der Berechnung der einzelnen Quadratsummen wird allerdings angenommen, dass alle Interaktionen, an denen dieser Term beteiligt ist, 0 sind. Typ II ist in `ezANOVA` voreingestellt.

```{r}
# QS-Typ 2
ezANOVA(conspiracy, dv = ET, wid = id, between = c(urban, edu), type = 2)
```

Typ III unterscheidet sich von Typ II nur darin, dass bei der Berechnung nicht angenommen wird, dass die Interaktionen 0 sind. Typ III ist z.B. in SPSS voreingestellt.

```{r}
# QS-Typ 3
ezANOVA(conspiracy, dv = ET, wid = id, between = c(urban, edu), type = 3)
```

Generell ist Typ II besser geeignet um die Quadratsummen von Haupteffekten zu bestimmen, wenn Interaktionen empirisch nicht von 0 verschieden sind. Wenn Interaktionen von 0 verschieden sind, wird (unabhängig vom QS-Typ) davon abgeraten die Haupteffekte zu interpretieren, sodass deren Bestimmung in diesem Fall wenig Relevanz hat. Die Terme höchste Ordnung (hier die Interaktion) sind zwischen Typ II und Typ III identisch, sodass die Interpretation der Interaktion durch die Wahl nicht beeinflusst wird.